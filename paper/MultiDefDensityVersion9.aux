\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plain}
\citation{mcc:95}
\citation{alla:07}
\citation{Beg:2006ly}
\citation{conf/miccai/BegMTY03}
\citation{Beg:2005qf}
\citation{cao:05}
\citation{dup:98}
\citation{Grenander:1998:CAE:309082.309089}
\citation{Miller:1999bh}
\citation{Miller:2006zr}
\citation{Miller:2001ve}
\citation{Trouve:1998ys}
\citation{ty:dq}
\citation{vaillant:04}
\citation{you:10}
\citation{Younes:2008}
\citation{Das:2011uq}
\citation{mcc:95}
\citation{and:11}
\citation{AnderesNychka}
\citation{ElMoselhy20127815}
\citation{and:11}
\citation{AnderesNychka}
\citation{ElMoselhy20127815}
\citation{you:10}
\citation{wahba:90}
\gdef\hy@title{A general spline representation for nonparametric and semiparametric density estimates using diffeomorphisms}
\thanksnewlabel{e1@email}{{anderes@stat.ucdavis.edu}{1}}
\thanksnewlabel{e2@email}{{mcoram@stanford.edu}{1}}
\thanksnewlabel{athanks}{{1}{1}}
\thanksnewlabel{athanks}{{1}{1}}
\thanksnewlabel{bthanks}{{2}{1}}
\thanksnewlabel{bthanks}{{2}{1}}
\gdef\hy@author{Ethan Anderes and Marc Coram}
\gdef\hy@subject{}
\gdef\hy@keywords{Euler-Lagrange, density estimation, penalized maximum likelihood, diffeomorphism}
\gdef\author@num{2}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{stein:04}
\citation{Younes:2008}
\@writefile{toc}{\contentsline {section}{\numberline {2}A rich class of diffeomorphisms}{2}{section.2}}
\newlabel{rich}{{2}{2}{A rich class of diffeomorphisms}{section.2}{}}
\newlabel{ood}{{1}{2}{A rich class of diffeomorphisms}{equation.2.1}{}}
\citation{you:10}
\citation{you:10}
\citation{you:10}
\citation{dup:98}
\newlabel{defV01}{{1}{3}{}{definition.1}{}}
\newlabel{ExistFlow}{{1}{3}{\cite {you:10}, \cite {dup:98}}{theorem.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Penalized maximum likelihood estimation}{3}{section.3}}
\newlabel{pmle}{{3}{3}{Penalized maximum likelihood estimation}{section.3}{}}
\newlabel{model1}{{2}{3}{Penalized maximum likelihood estimation}{equation.3.2}{}}
\citation{you:10}
\citation{dup:98}
\citation{dup:98}
\citation{dup:98}
\citation{dup:98}
\citation{dup:98}
\newlabel{energy1}{{3}{4}{Penalized maximum likelihood estimation}{equation.3.3}{}}
\newlabel{claim1}{{1}{4}{}{claim.1}{}}
\newlabel{exist}{{4}{4}{}{equation.3.4}{}}
\newlabel{decomp}{{5}{4}{Penalized maximum likelihood estimation}{equation.3.5}{}}
\newlabel{liminf}{{6}{4}{Penalized maximum likelihood estimation}{equation.3.6}{}}
\citation{cao:05}
\citation{you:10}
\@writefile{toc}{\contentsline {section}{\numberline {4}Spline representation from Euler-Lagrange}{6}{section.4}}
\newlabel{EL}{{4}{6}{Spline representation from Euler-Lagrange}{section.4}{}}
\newlabel{claim2}{{2}{6}{}{claim.2}{}}
\newlabel{ELeq}{{7}{6}{}{equation.4.7}{}}
\newlabel{dderE1}{{8}{6}{Spline representation from Euler-Lagrange}{equation.4.8}{}}
\newlabel{derE2}{{9}{6}{Spline representation from Euler-Lagrange}{equation.4.9}{}}
\citation{aro:50}
\citation{stein:04}
\newlabel{derE3}{{10}{7}{Spline representation from Euler-Lagrange}{equation.4.10}{}}
\newlabel{EEEl}{{11}{7}{Spline representation from Euler-Lagrange}{equation.4.11}{}}
\newlabel{CalE}{{12}{7}{Spline representation from Euler-Lagrange}{equation.4.12}{}}
\newlabel{ELeq0}{{13}{7}{Spline representation from Euler-Lagrange}{equation.4.13}{}}
\newlabel{InitialMom}{{14}{7}{Spline representation from Euler-Lagrange}{equation.4.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Connection to Stein's Method}{7}{section.5}}
\newlabel{steinSection}{{5}{7}{Connection to Stein's Method}{section.5}{}}
\citation{stein:04}
\citation{stein:81}
\citation{chen:05}
\newlabel{stein2}{{15}{8}{Connection to Stein's Method}{equation.5.15}{}}
\newlabel{ste}{{16}{8}{Connection to Stein's Method}{equation.5.16}{}}
\newlabel{ssmethod}{{17}{8}{Connection to Stein's Method}{equation.5.17}{}}
\newlabel{reg1}{{18}{8}{Connection to Stein's Method}{equation.5.18}{}}
\newlabel{stein}{{19}{8}{Connection to Stein's Method}{equation.5.19}{}}
\newlabel{reg2}{{20}{8}{Connection to Stein's Method}{equation.5.20}{}}
\citation{vaillant:04}
\citation{alla:07}
\@writefile{toc}{\contentsline {section}{\numberline {6}Nonparametric example}{9}{section.6}}
\newlabel{npe}{{6}{9}{Nonparametric example}{section.6}{}}
\newlabel{knots}{{21}{9}{Nonparametric example}{equation.6.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces In this example we compare two different knot configurations, in (\ref  {knots}), for generating nonparametric density estimates using approximate solutions to the Euler-Lagrange equation (\ref  {ELeq}). The left column of images shows two different density estimates (red), based on the same data set (blue), using two different knot configurations (top-left uses $10$ knots, bottom-left uses $30$ knots). The right column of images show the corresponding diagnostic curves which characterize the richness of the approximating subclass generated by the knots. The fact that the two diagnostic curves shown bottom-right are similar suggests that the $30$ knots used generate the approximating subclass by (\ref  {knots}) is sufficiently rich to reach the stationary points of the penalized log likelihood $E_\lambda $ given in (\ref  {energy1}). See Section \ref  {npe} for details.  }}{10}{figure.1}}
\newlabel{f2}{{1}{10}{In this example we compare two different knot configurations, in (\ref {knots}), for generating nonparametric density estimates using approximate solutions to the Euler-Lagrange equation (\ref {ELeq}). The left column of images shows two different density estimates (red), based on the same data set (blue), using two different knot configurations (top-left uses $10$ knots, bottom-left uses $30$ knots). The right column of images show the corresponding diagnostic curves which characterize the richness of the approximating subclass generated by the knots. The fact that the two diagnostic curves shown bottom-right are similar suggests that the $30$ knots used generate the approximating subclass by (\ref {knots}) is sufficiently rich to reach the stationary points of the penalized log likelihood $E_\lambda $ given in (\ref {energy1}). See Section \ref {npe} for details}{figure.1}{}}
\newlabel{diag1}{{22}{10}{Nonparametric example}{equation.6.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces   In this example we demonstrate that a small number of knots, in (\ref  {knots}), can be enough to approximate solutions to the Euler-Lagrange equation (\ref  {ELeq}). The left column of images shows two different density estimates (red), based on the same data set of size $n=240$ (grey histogram), using two different knot configurations (top-left uses $240$ knots, bottom-left uses $20$ knots). The right column of images show the corresponding diagnostic curves which characterize the richness of the approximating subclass generated by the knots. The fact that the two diagnostic curves shown bottom-right are nearly identical suggests that the $20$ knots used generate the approximating subclass by (\ref  {knots}) is sufficiently rich to reach the stationary points of the penalized log-likelihood $E_\lambda $ given in (\ref  {energy1}). See Section \ref  {npe} for details. }}{11}{figure.2}}
\newlabel{f3}{{2}{11}{In this example we demonstrate that a small number of knots, in (\ref {knots}), can be enough to approximate solutions to the Euler-Lagrange equation (\ref {ELeq}). The left column of images shows two different density estimates (red), based on the same data set of size $n=240$ (grey histogram), using two different knot configurations (top-left uses $240$ knots, bottom-left uses $20$ knots). The right column of images show the corresponding diagnostic curves which characterize the richness of the approximating subclass generated by the knots. The fact that the two diagnostic curves shown bottom-right are nearly identical suggests that the $20$ knots used generate the approximating subclass by (\ref {knots}) is sufficiently rich to reach the stationary points of the penalized log-likelihood $E_\lambda $ given in (\ref {energy1}). See Section \ref {npe} for details}{figure.2}{}}
\newlabel{eq:etakappa}{{25}{11}{Nonparametric example}{equation.6.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Semiparametric example}{12}{section.7}}
\newlabel{spe}{{7}{12}{Semiparametric example}{section.7}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Compute the semiparametric estimates $\mathaccentV {hat}05E\theta , \mathaccentV {hat}05E\phi $}}{12}{algorithm.1}}
\newlabel{alg2}{{1}{12}{Semiparametric example}{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  In this example we demonstrate that by parametrically modeling the target distribution one can produce flexible semiparametric density estimates. The left column of histograms show the data (the same histogram plotted twice) sampled from the population density shown in black. Two semiparametric estimates are shown in red which correspond to different parametric targets. The estimated target distribution is shown in green on the left column of images. The right column of images show the corresponding diagnostic curves which characterize the richness of the approximating subclass generated by the knots ($\lambda v_0$ is plotted in black and $\mathcal  D_0^v$ is plotted in dashed-green). See Section \ref  {spe} for details.  }}{13}{figure.3}}
\newlabel{f4}{{3}{13}{In this example we demonstrate that by parametrically modeling the target distribution one can produce flexible semiparametric density estimates. The left column of histograms show the data (the same histogram plotted twice) sampled from the population density shown in black. Two semiparametric estimates are shown in red which correspond to different parametric targets. The estimated target distribution is shown in green on the left column of images. The right column of images show the corresponding diagnostic curves which characterize the richness of the approximating subclass generated by the knots ($\lambda v_0$ is plotted in black and $\mathcal D_0^v$ is plotted in dashed-green). See Section \ref {spe} for details}{figure.3}{}}
\citation{you:10}
\citation{you:10}
\citation{you:10}
\@writefile{toc}{\contentsline {section}{\numberline {8}Discussion}{14}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Technical Details}{14}{appendix.A}}
\newlabel{TD}{{A}{14}{Technical Details}{appendix.A}{}}
\citation{you:10}
\newlabel{Hspace}{{1}{15}{}{proposition.1}{}}
\newlabel{PropDef}{{2}{15}{}{proposition.2}{}}
\newlabel{div}{{26}{15}{}{equation.A.26}{}}
\citation{you:10}
\citation{you:10}
\citation{hor:91}
\newlabel{Contract}{{27}{16}{Technical Details}{equation.A.27}{}}
\newlabel{gg}{{29}{16}{Technical Details}{equation.A.29}{}}
\citation{rud:66}
\citation{you:10}
\citation{dup:98}
\citation{rud:66}
\newlabel{222}{{30}{17}{}{equation.A.30}{}}
\newlabel{777}{{31}{17}{}{equation.A.31}{}}
\newlabel{uugg}{{32}{17}{Technical Details}{equation.A.32}{}}
\citation{you:10}
\newlabel{proo}{{3}{19}{}{proposition.3}{}}
\newlabel{111}{{33}{19}{}{equation.A.33}{}}
\newlabel{888}{{34}{19}{}{equation.A.34}{}}
\newlabel{hhhh1}{{35}{19}{Technical Details}{equation.A.35}{}}
\newlabel{hhhh2}{{36}{19}{Technical Details}{equation.A.36}{}}
\citation{you:10}
\citation{you:10}
\citation{you:10}
\citation{you:10}
\citation{you:10}
\citation{you:10}
\citation{you:10}
\newlabel{uuuu}{{37}{20}{Technical Details}{equation.A.37}{}}
\newlabel{fine}{{38}{20}{Technical Details}{equation.A.38}{}}
\newlabel{811}{{39}{20}{Technical Details}{equation.A.39}{}}
\newlabel{811}{{41}{20}{Technical Details}{equation.A.41}{}}
\newlabel{rrmark}{{42}{20}{Technical Details}{equation.A.42}{}}
\newlabel{pass}{{43}{20}{Technical Details}{equation.A.43}{}}
\citation{cou:36}
\@writefile{toc}{\contentsline {section}{\numberline {B}Radial kernel derivatives}{22}{appendix.B}}
\newlabel{yy1}{{44}{22}{}{equation.B.44}{}}
\newlabel{yy2}{{45}{22}{}{equation.B.45}{}}
\newlabel{yy3}{{46}{22}{}{equation.B.46}{}}
\newlabel{yy4}{{47}{22}{}{equation.B.47}{}}
\newlabel{yy5}{{48}{22}{}{equation.B.48}{}}
\newlabel{yy6}{{49}{22}{}{equation.B.49}{}}
\newlabel{IamSmall}{{52}{23}{Radial kernel derivatives}{equation.B.52}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Numerical techniques: geodesic and transpose flows}{23}{appendix.C}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.1}Geodesic flow when $v^t(x)=\DOTSB \sum@ \slimits@ _{j=1}^N \eta ^t_j R(x,\kappa ^t_j) $ on $\mathbb  R^1$}{23}{subsection.C.1}}
\newlabel{EL}{{54}{24}{Geodesic flow when $v^t(x)=\sum _{j=1}^N \eta ^t_j R(x,\kappa ^t_j) $ on $\Bbb R^1$}{equation.C.54}{}}
\newlabel{EL}{{55}{24}{Geodesic flow when $v^t(x)=\sum _{j=1}^N \eta ^t_j R(x,\kappa ^t_j) $ on $\Bbb R^1$}{equation.C.55}{}}
\newlabel{updateEta}{{56}{24}{Geodesic flow when $v^t(x)=\sum _{j=1}^N \eta ^t_j R(x,\kappa ^t_j) $ on $\Bbb R^1$}{equation.C.56}{}}
\newlabel{updateKnots}{{57}{24}{Geodesic flow when $v^t(x)=\sum _{j=1}^N \eta ^t_j R(x,\kappa ^t_j) $ on $\Bbb R^1$}{equation.C.57}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2}Perturbing $\eta $ and $\kappa $ at $t=0$}{25}{subsection.C.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.3}Simplify the ode flow for $(\delta \eta ,\delta \kappa , \delta \phi , \delta \nabla \phi )$}{25}{subsection.C.3}}
\newlabel{simplifiedODE}{{C.3}{25}{Simplify the ode flow for $(\delta \eta ,\delta \kappa , \delta \phi , \delta \nabla \phi )$}{subsection.C.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.4}Transpose flow when $v^t(x)=\DOTSB \sum@ \slimits@ _{j=1}^N \eta ^t_j R(x,\kappa ^t_j) $ on $\mathbb  R^1$}{26}{subsection.C.4}}
\newlabel{simSys}{{71}{26}{Transpose flow when $v^t(x)=\sum _{j=1}^N \eta ^t_j R(x,\kappa ^t_j) $ on $\Bbb R^1$}{equation.C.71}{}}
\@writefile{toc}{\contentsline {paragraph}{Deriving the transpose flow:}{28}{section*.1}}
\newlabel{forwardTT}{{91}{28}{Deriving the transpose flow:}{equation.C.91}{}}
\bibdata{refs}
\bibcite{alla:07}{1}
\bibcite{and:11}{2}
\bibcite{AnderesNychka}{3}
\bibcite{aro:50}{4}
\newlabel{Eulerian}{{92}{29}{Deriving the transpose flow:}{equation.C.92}{}}
\newlabel{oouoo}{{93}{29}{Deriving the transpose flow:}{equation.C.93}{}}
\newlabel{likeforward}{{94}{29}{Deriving the transpose flow:}{equation.C.94}{}}
\@writefile{toc}{\contentsline {section}{References}{29}{section*.3}}
\bibcite{Beg:2006ly}{5}
\bibcite{conf/miccai/BegMTY03}{6}
\bibcite{Beg:2005qf}{7}
\bibcite{cao:05}{8}
\bibcite{chen:05}{9}
\bibcite{cou:36}{10}
\bibcite{dup:98}{11}
\bibcite{Das:2011uq}{12}
\bibcite{Grenander:1998:CAE:309082.309089}{13}
\bibcite{hor:91}{14}
\bibcite{mcc:95}{15}
\bibcite{Miller:1999bh}{16}
\bibcite{Miller:2006zr}{17}
\bibcite{Miller:2001ve}{18}
\bibcite{ElMoselhy20127815}{19}
\bibcite{rud:66}{20}
\bibcite{stein:81}{21}
\bibcite{stein:04}{22}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Compute the gradient of the log likelihood at initial $\eta _\text  {\relax \fontsize  {5}{6}\selectfont  init},\kappa _\text  {\relax \fontsize  {5}{6}\selectfont  init}$}}{30}{algorithm.2}}
\newlabel{alg2}{{2}{30}{Deriving the transpose flow:}{algorithm.2}{}}
\bibcite{Trouve:1998ys}{23}
\bibcite{ty:dq}{24}
\bibcite{vaillant:04}{25}
\bibcite{wahba:90}{26}
\bibcite{you:10}{27}
\bibcite{Younes:2008}{28}
